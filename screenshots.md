# Screenshots
The following screenshots show how the chatbot works.

When the chatbot starts, on the righthand pane it displays a natural language representation of the theory that the chatbot Agent will use to generate subsequent responses:

![screenshot 1](assets/1.png)

By clicking on the recycling-like button on the top right we can instead see the WFFs that constitute the theory in the right-hand pane.

![screenshot 2](assets/2.png)

We start by asking the chatbot a very simple question, we first see indications of what the agent is doing:

![screenshot 3](assets/3.png)

and, finally, we see the result:

![screenshot 4](assets/4.png)

By clicking on the assistant's response speech bubble, we see an alternative view of the response:

![screenshot 5](assets/5.png)

We can also ask more complicated questions:

![screenshot 6](assets/6.png)

And, like before, we can click on the assistant response to see the
alternative view. Note here that the natural language statement has
been converted into a logical statement that is non-trivial:

![screenshot 7](assets/7.png)

